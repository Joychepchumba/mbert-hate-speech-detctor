import streamlit as st
import torch
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from transformers import AutoModelForSequenceClassification, AutoTokenizer
import uvicorn
import threading

# ‚úÖ Initialize FastAPI
app = FastAPI()

# ‚úÖ Enable CORS for Power BI access
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allow requests from any domain
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ‚úÖ Load Model & Tokenizer (Cache to prevent reloading)
@st.cache_resource()
def load_model():
    model_name = "JCKipkemboi/hate_speech_detector_mbert"  # mBERT for multilingual support
    model = AutoModelForSequenceClassification.from_pretrained(model_name)
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    return model, tokenizer

model, tokenizer = load_model()

# ‚úÖ FastAPI Request Schema
class TextInput(BaseModel):
    text: str

# ‚úÖ API Endpoint for Predictions
@app.post("/predict")
def predict(input: TextInput):
    """Classifies text as Hate Speech or Not Hate Speech (Multilingual)"""
    inputs = tokenizer(input.text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probabilities = torch.nn.functional.softmax(logits, dim=-1)
        prediction = torch.argmax(probabilities, dim=-1).item()
    
    label = "Hate Speech" if prediction == 1 else "Not Hate Speech"
    confidence = probabilities[0][prediction].item() * 100

    return {
        "text": input.text,
        "prediction": label,
        "confidence": f"{confidence:.2f}%",
        "message": "This model supports multiple languages using mBERT."
    }

# ‚úÖ Streamlit UI
def streamlit_ui():
    # Set page config as the first command in the function
    st.set_page_config(page_title="üåç Multilingual Hate Speech Detector", page_icon="üõë", layout="centered")
    
    st.title("üåç Multilingual Hate Speech Detector")
    st.write("This tool detects hate speech across multiple languages using mBERT (Multilingual BERT).")

    st.write("Enter a sentence below to check if it's **Hate Speech** or **Not Hate Speech**.")

    # User Input
    text = st.text_area("üìù Enter your text:", height=100)

    # Streamlit Prediction Function
    def streamlit_predict(text):
        inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
        with torch.no_grad():
            outputs = model(**inputs)
            logits = outputs.logits
            probabilities = torch.nn.functional.softmax(logits, dim=-1)
            prediction = torch.argmax(probabilities, dim=-1).item()
        
        label = "Hate Speech" if prediction == 1 else "Not Hate Speech"
        confidence = probabilities[0][prediction].item() * 100
        return label, confidence

    # Example Inputs
    with st.expander("üí° Example Inputs"):
        st.write("üîπ *You are stupid!* ‚Üí Hate Speech (English)")
        st.write("üîπ *Tu es horrible!* ‚Üí Hate Speech (French)")
        st.write("üîπ *Hola amigo, c√≥mo est√°s?* ‚Üí Not Hate Speech (Spanish)")

    # Predict Button
    if st.button("üöÄ Predict"):
        if text.strip():
            with st.spinner("üîÑ Processing... Please wait"):
                label, confidence = streamlit_predict(text)
            st.success(f"‚úÖ **Prediction:** {label}")
            st.write(f"üìä **Confidence:** {confidence:.2f}%")
        else:
            st.warning("‚ö†Ô∏è Please enter some text before predicting.")

    # Footer
    st.markdown(
        """
        ---
        **Note:** This model uses **mBERT** (Multilingual BERT) to detect hate speech across different languages.
        """,
        unsafe_allow_html=True,
    )

# ‚úÖ Run FastAPI & Streamlit Simultaneously
def run_fastapi():
    uvicorn.run(app, host="0.0.0.0", port=8000)

if __name__ == "__main__":
    # Run FastAPI in a separate thread (optional for serving both APIs)
    threading.Thread(target=run_fastapi, daemon=True).start()
    # Directly call Streamlit UI
    streamlit_ui()
